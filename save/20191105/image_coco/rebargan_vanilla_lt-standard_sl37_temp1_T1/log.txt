====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: rebargan
>>> dataset: image_coco
>>> model_type: vanilla
>>> loss_type: standard
>>> if_real_data: 1
>>> cuda: 0
>>> device: -1
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: uniform
>>> samples_num: 10000
>>> vocab_size: 4683
>>> mle_epoch: 120
>>> adv_epoch: 200
>>> inter_epoch: 10
>>> batch_size: 64
>>> max_seq_len: 37
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.01
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 5
>>> adv_log_step: 1
>>> train_data: dataset/oracle.txt
>>> test_data: dataset/testdata/oracle_test.txt
>>> temp_adpt: exp
>>> temperature: 1
>>> eta: 1
>>> learn_temperature: 1
>>> learn_eta: 1
>>> ora_pretrain: 1
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 1
>>> rollout_num: 4
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 4
>>> adv_d_epoch: 2
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> log_file: log/log_1105_2332_34.txt
>>> save_root: save/20191105/image_coco/rebargan_vanilla_lt-standard_sl37_temp1_T1/
>>> signal_file: run_signal.txt
>>> tips: vanilla RebarGAN
====================================================================================================
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : pre_loss = 2.5639, BLEU-[2, 3, 4, 5] = [0.343, 0.137, 0.076, 0.056], gen_NLL = 1.6958, self_bleu = [0.291],
[MLE-GEN] epoch 5 : pre_loss = 1.1844, BLEU-[2, 3, 4, 5] = [0.823, 0.583, 0.354, 0.219], gen_NLL = 1.1466, self_bleu = [0.608],
[MLE-GEN] epoch 10 : pre_loss = 1.0313, BLEU-[2, 3, 4, 5] = [0.857, 0.659, 0.452, 0.294], gen_NLL = 0.9989, self_bleu = [0.686],
[MLE-GEN] epoch 15 : pre_loss = 0.9432, BLEU-[2, 3, 4, 5] = [0.886, 0.693, 0.477, 0.308], gen_NLL = 0.9182, self_bleu = [0.697],
[MLE-GEN] epoch 20 : pre_loss = 0.8885, BLEU-[2, 3, 4, 5] = [0.9, 0.721, 0.517, 0.346], gen_NLL = 0.8691, self_bleu = [0.708],
[MLE-GEN] epoch 25 : pre_loss = 0.8522, BLEU-[2, 3, 4, 5] = [0.907, 0.729, 0.508, 0.333], gen_NLL = 0.8378, self_bleu = [0.747],
[MLE-GEN] epoch 30 : pre_loss = 0.8275, BLEU-[2, 3, 4, 5] = [0.914, 0.752, 0.548, 0.369], gen_NLL = 0.8168, self_bleu = [0.746],
[MLE-GEN] epoch 35 : pre_loss = 0.8127, BLEU-[2, 3, 4, 5] = [0.914, 0.758, 0.557, 0.382], gen_NLL = 0.8094, self_bleu = [0.728],
[MLE-GEN] epoch 40 : pre_loss = 0.7937, BLEU-[2, 3, 4, 5] = [0.921, 0.76, 0.561, 0.388], gen_NLL = 0.7896, self_bleu = [0.734],
